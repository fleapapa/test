{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/tmp/parquet/trip_data/trip_data_1.csv\n",
      "/data/tmp/parquet/trip_data/trip_data_10.csv\n",
      "/data/tmp/parquet/trip_data/trip_data_11.csv\n",
      "/data/tmp/parquet/trip_data/trip_data_12.csv\n",
      "/data/tmp/parquet/trip_data/trip_data_2.csv\n",
      "/data/tmp/parquet/trip_data/trip_data_3.csv\n",
      "/data/tmp/parquet/trip_data/trip_data_4.csv\n",
      "/data/tmp/parquet/trip_data/trip_data_5.csv\n",
      "/data/tmp/parquet/trip_data/trip_data_6.csv\n",
      "/data/tmp/parquet/trip_data/trip_data_7.csv\n",
      "/data/tmp/parquet/trip_data/trip_data_8.csv\n",
      "/data/tmp/parquet/trip_data/trip_data_9.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "csv_files = glob.glob('/data/tmp/parquet/trip_data/*.csv')\n",
    "csv_files = sorted(csv_files, key=lambda f: f)\n",
    "print '\\n'.join(csv_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssql = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dfs = []\n",
    "for csv_file in csv_files:\n",
    "    tstart = time.time()\n",
    "    df = ssql.read.format('com.databricks.spark.csv')\\\n",
    "        .options(header='false', inferschema='true')\\\n",
    "        .load(csv_file)\n",
    "    dfs.append(df)\n",
    "    print '%s = %d' % (csv_file, time.time() - tstart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# write all dataframes to a parquet \n",
    "for df in dfs:\n",
    "    df.write.mode(\"append\").parquet(\"/data/tmp/parquet/trip_data.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load the parquet back \n",
    "pdf = ssql.read.parquet(\"/data/tmp/parquet/trip_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173179771\n",
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print pdf.count()\n",
    "pdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+------------------------+\n",
      "|count(1)|avg(CAST(_c8 AS DOUBLE))|avg(CAST(_c9 AS DOUBLE))|\n",
      "+--------+------------------------+------------------------+\n",
      "|  533566|       808.8370323446396|      3.1116808792164283|\n",
      "+--------+------------------------+------------------------+\n",
      "\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 6.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pdf.createOrReplaceTempView(\"trips\")\n",
    "df = ssql.sql('select count(*), avg(_c8), avg(_c9) from trips where _c12 > 37 and _c12 < 50')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# partition the dataframes in two parquets to\n",
    "# test performance of 'join'\n",
    "\n",
    "# write one half of dataframes to a parquet 1\n",
    "for df in dfs[0:len(dfs)/2]:\n",
    "    df.write.mode(\"append\").parquet(\"/data/tmp/parquet/trip_data.parquet1\")\n",
    "\n",
    "for df in dfs[len(dfs)/2:]:\n",
    "    df.write.mode(\"append\").parquet(\"/data/tmp/parquet/trip_data.parquet2\")\n",
    "\n",
    "pdf1 = ssql.read.parquet(\"/data/tmp/parquet/trip_data.parquet1\")\n",
    "pdf2 = ssql.read.parquet(\"/data/tmp/parquet/trip_data.parquet2\")\n",
    "pdf1.createOrReplaceTempView(\"t1\")\n",
    "pdf2.createOrReplaceTempView(\"t2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = ssql.sql('select avg(t1._c8), avg(t2._c9) \\\n",
    "    from t1, t2 \\\n",
    "    where t1._c12 > 10 and t1._c12 < 37\\\n",
    "    and   t2._c12 > 37 and t2._c12 < 50\\\n",
    "    and   t1._c12 < t2._c12\\\n",
    "    ')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = ssql.sql('select count(*), avg(_c8), avg(_c9) from t2 where _c12 > 37 and _c12 < 41')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdf1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# compare parquet vs csv performance\n",
    "cdf = ssql.read.format('com.databricks.spark.csv')\\\n",
    "    .options(header='false', inferschema='true')\\\n",
    "    .load('/data/tmp/parquet/trip_data/*.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cdf.createOrReplaceTempView(\"trips\")\n",
    "df = ssql.sql('select avg(_c8), avg(_c9) from trips where _c12 > 37 and _c12 < 50')\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
